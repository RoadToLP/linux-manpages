.TH "nft_pipapo_avx2_lookup_4b_2" 9 "nft_pipapo_avx2_lookup_4b_2" "May 2021" "Kernel Hacker's Manual" LINUX
.SH NAME
nft_pipapo_avx2_lookup_4b_2 \- AVX2-based lookup for 2 four-bit groups
.SH SYNOPSIS
.B "int" nft_pipapo_avx2_lookup_4b_2
.BI "(unsigned long *map "  ","
.BI "unsigned long *fill "  ","
.BI "struct nft_pipapo_field *f "  ","
.BI "int offset "  ","
.BI "const u8 *pkt "  ","
.BI "bool first "  ","
.BI "bool last "  ");"
.SH ARGUMENTS
.IP "map" 12
Previous match result, used as initial bitmap
.IP "fill" 12
Destination bitmap to be filled with current match result
.IP "f" 12
Field, containing lookup and mapping tables
.IP "offset" 12
Ignore buckets before the given index, no bits are filled there
.IP "pkt" 12
Packet data, pointer to input nftables register
.IP "first" 12
If this is the first field, don't source previous result
.IP "last" 12
Last field: stop at the first match and return bit index
.SH "DESCRIPTION"
Load buckets from lookup table corresponding to the values of each 4-bit
group of packet bytes, and perform a bitwise intersection between them. If
this is the first field in the set, simply AND the buckets together
(equivalent to using an all-ones starting bitmap), use the provided starting
bitmap otherwise. Then call \fBnft_pipapo_avx2_refill\fP to generate the next
working bitmap, \fIfill\fP.

This is used for 8-bit fields (i.e. protocol numbers).

Out-of-order (and superscalar) execution is vital here, so it's critical to
avoid false data dependencies. CPU and compiler could (mostly) take care of
this on their own, but the operation ordering is explicitly given here with
a likely execution order in mind, to highlight possible stalls. That's why
a number of logically distinct operations (i.e. loading buckets, intersecting
buckets) are interleaved.
.SH "RETURN"
-1 on no match, rule index of match if \fIlast\fP, otherwise first long
word index to be checked next (i.e. first filled word).
